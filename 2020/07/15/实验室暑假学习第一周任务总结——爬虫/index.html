<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="任务需求&amp;emsp;&amp;emsp;在贝壳租房网站（这里我选择的城市是天津）爬取50页房源信息，包括房源编号、所在城市、所在区县、所在街道或地区、小区名称、面积、朝向、月租、计费方式、室、厅、卫、入住、租期、看房、所在楼层、总楼层、电梯、车位、用水、用电、燃气、采暖等信息。将信息写入CSV文件保存，以备">
    

    <!--Author-->
    
        <meta name="author" content="John Doe">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="实验室暑假学习第一周任务总结——爬虫"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="Welcome to CCH21&#39;s Blog"/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>实验室暑假学习第一周任务总结——爬虫 - Welcome to CCH21&#39;s Blog</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Google Analytics -->
    


</head>


<body>

<div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="/">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/about.html">
                    About
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="/contact.html">
                    Contact
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
    </div>
</header>

        <section class="main">
            
<div class="post">

    <div class="post-header">
        <h1 class="title">
            <a href="/2020/07/15/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9A%91%E5%81%87%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E5%91%A8%E4%BB%BB%E5%8A%A1%E6%80%BB%E7%BB%93%E2%80%94%E2%80%94%E7%88%AC%E8%99%AB/">
                实验室暑假学习第一周任务总结——爬虫
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2020-07-15</span>
            
            
            
        </div>
    </div>

    <div class="content">

        <!-- Gallery -->
        

        <!-- Post Content -->
        <h2 id="任务需求"><a href="#任务需求" class="headerlink" title="任务需求"></a>任务需求</h2><p>&emsp;&emsp;在<a href="https://tj.zu.ke.com/zufang" target="_blank" rel="noopener">贝壳租房</a>网站（这里我选择的城市是天津）爬取50页房源信息，包括房源编号、所在城市、所在区县、所在街道或地区、小区名称、面积、朝向、月租、计费方式、室、厅、卫、入住、租期、看房、所在楼层、总楼层、电梯、车位、用水、用电、燃气、采暖等信息。将信息写入CSV文件保存，以备后续任务使用。  </p>
<h2 id="对任务需求的分析"><a href="#对任务需求的分析" class="headerlink" title="对任务需求的分析"></a>对任务需求的分析</h2><p>&emsp;&emsp;这是一个关于爬虫的任务，那么一些爬虫常用的模块（如<code>requests</code>, <code>bs4</code>等）是必不可少的。<br>&emsp;&emsp;需求中有提到“爬取50页数据”，看到这里很自然地就会想到使用循环来解决。打开贝壳租房网，翻页观察URL的变化并寻找规律，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200714231910790.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200714231839432.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&emsp;&emsp;不难发现，URL的“模板”是<code>https://tj.zu.ke.com/zufang/pg[对应的页码]/#contentList</code>。那么，爬取50页数据就可以使用<code>for</code>循环来解决，循环变量的范围设置为<code>range(1, 51)</code>，将其作为页码拼接到“模板”URL中，对这些URL分别发起请求爬取数据即可。<br>&emsp;&emsp;接下来的问题是，如何找到某一个房源的具体信息呢？<br>&emsp;&emsp;我们点击右键检查元素，进入网页的HTML源代码查看，会发现一个名为<code>data-house_code</code>的值。大胆猜测一下，它和房源具体信息页的URL存在一些关联。<br><img src="https://img-blog.csdnimg.cn/20200714233646388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&emsp;&emsp;点击房源进入详情页，我们发现URL中恰好包含前面看到的<code>data-house_code</code>值。事实上，这个值正是与房源一一对应的唯一编号。<br><img src="https://img-blog.csdnimg.cn/20200714234254848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>&emsp;&emsp;最后就是对HTML代码抽丝剥茧找出所需要的数据并写入CSV文件了。这里可以使用<code>bs4</code>来解析HTML源代码，也可以使用正则表达式或者XPath解析。我使用的是<code>bs4</code>和正则表达式结合解析HTML的方法。详细的实现过程可以参考下面的Python代码。  </p>
<h2 id="Python源代码"><a href="#Python源代码" class="headerlink" title="Python源代码"></a>Python源代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python3</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import csv</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">head = [&apos;房源编号&apos;, &apos;所在城市&apos;, &apos;所在区县&apos;, &apos;所在街道或地区&apos;, &apos;小区名称&apos;, &apos;面积&apos;, &apos;租赁方式&apos;, &apos;朝向&apos;, &apos;月租&apos;, &apos;计费方式&apos;, &apos;室&apos;, &apos;厅&apos;,</span><br><span class="line">        &apos;卫&apos;, &apos;入住&apos;, &apos;租期&apos;, &apos;看房&apos;, &apos;所在楼层&apos;, &apos;总楼层&apos;, &apos;电梯&apos;, &apos;车位&apos;, &apos;用水&apos;, &apos;用电&apos;, &apos;燃气&apos;, &apos;采暖&apos;]    # 写入文件的标题行</span><br><span class="line">headers = &#123;&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0) Gecko/20100101 Firefox/78.0&apos;&#125;</span><br><span class="line">with open(&apos;TianjinRentHouseInfo.csv&apos;, &apos;w&apos;, newline=&apos;&apos;) as csv_out_file:</span><br><span class="line">    filewriter = csv.writer(csv_out_file)</span><br><span class="line">    filewriter.writerow(head)</span><br><span class="line">    for page in range(1, 51):</span><br><span class="line">        url = &apos;https://tj.zu.ke.com/zufang/pg&apos; + str(page) + &apos;/#contentList&apos;</span><br><span class="line">        response = requests.get(url=url, headers=headers)</span><br><span class="line">        page_text = response.text</span><br><span class="line">        soup = BeautifulSoup(page_text, &apos;html.parser&apos;)</span><br><span class="line">        div_list = soup.find_all(class_=&apos;content__list--item&apos;)</span><br><span class="line">        codes = []  # 存储房源编号的列表</span><br><span class="line">        areas = []  # 存储房源地区的列表</span><br><span class="line">        for div in div_list:</span><br><span class="line">            code = re.search(r&apos;data-house_code=&quot;(.*?)&quot; &apos;, str(div)).group()[17:-2]</span><br><span class="line">            codes.append(code)</span><br><span class="line">        p_list = soup.find_all(class_=&apos;content__list--item--des&apos;)</span><br><span class="line">        for p in p_list:</span><br><span class="line">            a_list = p.find_all(&apos;a&apos;)</span><br><span class="line">            area = []</span><br><span class="line">            for i in range(len(a_list)):</span><br><span class="line">                a_text = a_list[i].text</span><br><span class="line">                area.append(a_text)</span><br><span class="line">            areas.append(area)</span><br><span class="line">        for i in range(len(codes)):</span><br><span class="line">            info = []  # 存储房源信息的列表</span><br><span class="line">            info.extend([codes[i], &apos;天津&apos;] + areas[i])</span><br><span class="line">            url = &apos;https://tj.zu.ke.com/zufang/&apos; + codes[i] + &apos;.html&apos;</span><br><span class="line">            response = requests.get(url=url, headers=headers)</span><br><span class="line">            page_text = response.text</span><br><span class="line">            soup = BeautifulSoup(page_text, &apos;html.parser&apos;)</span><br><span class="line">            ul_text = soup.find(&apos;ul&apos;, class_=&apos;content__aside__list&apos;).text</span><br><span class="line">            div_text = soup.find(&apos;div&apos;, class_=&apos;content__aside--title&apos;).text</span><br><span class="line">            S = re.search(r&apos; (.*?)㎡&apos;, ul_text).group()[1:]    # 面积</span><br><span class="line">            lease = re.search(r&apos;租赁方式：(.*?)\n&apos;, ul_text).group()[5:-1]    # 租赁方式</span><br><span class="line">            aspect = re.search(r&apos;朝向楼层：(.*?) &apos;, ul_text).group()[5:-1]    # 朝向</span><br><span class="line">            price = re.search(r&apos;([0-9]*?)元/月&apos;, div_text).group()    # 月租</span><br><span class="line">            try:</span><br><span class="line">                charge_mode = re.search(r&apos;\((.*?)\)&apos;, div_text).group()[1:-1]    # 计费方式</span><br><span class="line">            except AttributeError:</span><br><span class="line">                charge_mode = &apos;None&apos;</span><br><span class="line">            room = re.search(r&apos;([0-9*?])室&apos;, ul_text).group()    # 几室</span><br><span class="line">            hall = re.search(r&apos;([0-9*?])厅&apos;, ul_text).group()    # 几厅</span><br><span class="line">            toilet = re.search(r&apos;([0-9*?])卫&apos;, ul_text).group()    # 几卫</span><br><span class="line">            info.extend([S, lease, aspect, price, charge_mode, room, hall, toilet])</span><br><span class="line">            div = soup.find(&apos;div&apos;, class_=&apos;content__article__info&apos;)</span><br><span class="line">            ul_list = div.find_all(&apos;ul&apos;)</span><br><span class="line">            ul_text = &apos;&apos;</span><br><span class="line">            for ul in ul_list:</span><br><span class="line">                ul_text += ul.text</span><br><span class="line">            check_in = re.search(r&apos;入住：(.*?)\n&apos;, ul_text).group()[3:-1]    # 入住</span><br><span class="line">            term = re.search(r&apos;租期：(.*?)\n&apos;, ul_text).group()[3:-1]    # 租期</span><br><span class="line">            see_house = re.search(r&apos;看房：(.*?)\n&apos;, ul_text).group()[3:-1]    # 看房</span><br><span class="line">            floor = re.search(r&apos;楼层：(.*?)/&apos;, ul_text).group()[3:-1]    # 所在楼层</span><br><span class="line">            total_floor = re.search(r&apos;/(.*?)\n&apos;, ul_text).group()[1:-1]    # 总楼层</span><br><span class="line">            lift = re.search(r&apos;电梯：(.*?)\n&apos;, ul_text).group()[3:-1]    # 电梯</span><br><span class="line">            stall = re.search(r&apos;车位：(.*?)\n&apos;, ul_text).group()[3:-1]    # 车位</span><br><span class="line">            water = re.search(r&apos;用水：(.*?)\n&apos;, ul_text).group()[3:-1]    # 用水</span><br><span class="line">            elec = re.search(r&apos;用电：(.*?)\n&apos;, ul_text).group()[3:-1]    # 用电</span><br><span class="line">            gas = re.search(r&apos;燃气：(.*?)\n&apos;, ul_text).group()[3:-1]    # 燃气</span><br><span class="line">            heating = re.search(r&apos;采暖：(.*?)\n&apos;, ul_text).group()[3:-1]    # 采暖</span><br><span class="line">            info.extend([check_in, term, see_house, floor, total_floor, lift, stall, water, elec, gas, heating])</span><br><span class="line">            print(info[0], &apos;写入成功&apos;)</span><br><span class="line">            filewriter.writerow(info)</span><br></pre></td></tr></table></figure>

<p>&emsp;&emsp;在写代码的过程中我遇到了一个问题，在用正则表达式匹配“计费方式”的时候，会有匹配不到结果而报<code>AttributeError</code>错误的情况出现。经过排查，我发现有的房源详情页并不存在“计费方式”的字样，自然无法匹配。可以使用<code>try-except</code>结构来解决这个问题，详情请参考上述代码第50-53行。<br><img src="https://img-blog.csdnimg.cn/20200714235435645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200714235201499.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><p>&emsp;&emsp;运行后可得到一个CSV文件，其中共包含1503条房源数据。<br><img src="https://img-blog.csdnimg.cn/20200714235522473.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NTU0MDEw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>

    </div>

    

    

    <!-- Comments -->
    

</div>
        </section>

    </div>
</div>


</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    I'd walk a million miles just to see your smile. 
                </p>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="/2020/07/23/%E3%80%90Linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E3%80%91%E6%96%87%E4%BB%B6%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/">【Linux自学笔记】文件相关命令</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/07/22/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9A%91%E5%81%87%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E5%91%A8%E4%BB%BB%E5%8A%A1%E6%80%BB%E7%BB%93-%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/">实验室暑假学习第二周任务总结--简单的数据处理</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/07/22/%E3%80%90Linux%E8%87%AA%E5%AD%A6%E7%AC%94%E8%AE%B0%E3%80%91%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BB%8B%E7%BB%8D%E4%B8%8E%E7%9B%AE%E5%BD%95%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/">【Linux自学笔记】常用命令介绍与目录相关命令</a>
            </li>
            
            <li>
                <a class="footer-post" href="/2020/07/21/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9A%91%E5%81%87%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E5%91%A8%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/">实验室暑假学习第二周算法总结</a>
            </li>
            
        </ul>
    </div>



            
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/CCH21" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:1398635912@qq.com" target="_blank" rel="noopener">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @Untitled. All right reserved | Design & Hexo <a href="http://www.codeblocq.com/" target="_blank" rel="noopener">Jonathan Klughertz</a>
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->
<script src="/js/main.js"></script>

<!-- Disqus Comments -->



</body>

</html>